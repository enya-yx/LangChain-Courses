{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ptvadYguJkgJbf6zSffg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enya-yx/LangChain-Courses/blob/main/langgraph_memory_semantic_email_assistant_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"langchain-google-genai\" \"langchain\" \"langchain-core\" \"langgraph-prebuilt\" \"google-generativeai\" \"langchain_community\" \"docarray\" \"langchain_experimental\" \"aiosqlite\""
      ],
      "metadata": {
        "id": "sIdyIP6YPtKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langmem"
      ],
      "metadata": {
        "id": "XW_aVycGWxWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('google_api_key')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily_api_key')\n",
        "\n",
        "# Configure the generative AI library with your API key\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
      ],
      "metadata": {
        "id": "6gPZp3CQXQzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f45eca2-681c-468e-ab5d-2b78c7d9655c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Define llm\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    #model=\"gemini-1.5-flash-001\",\n",
        "    temperature=0,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "UL4c9YZWO0X7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "StepI. Define classifications and store/memory"
      ],
      "metadata": {
        "id": "yUnd4h0fpKHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile = {\n",
        "    \"name\": \"John\",\n",
        "    \"full_name\": \"John Doe\",\n",
        "    \"user_profile_background\": \"Senior software engineer leading a team\"\n",
        "}\n",
        "prompt_instructions = {\n",
        "  \"triage_rules\": {\n",
        "      \"ignore\": \"Marketing newsletters, spam emails\",\n",
        "      \"notify\": \"Team member out sick, build system notifications.\",\n",
        "      \"respond\": \"Direct questions from team members, meeting requests.\"\n",
        "  },\n",
        "  \"agent_instructions\": \"Use these tools when appropriate to help\"\n",
        "}"
      ],
      "metadata": {
        "id": "PDrM9GU4M1_V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output structure\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "class Router(BaseModel):\n",
        "  \"\"\"Analyze the unread email and route it according to its content\"\"\"\n",
        "\n",
        "  reasoning: str = Field(\n",
        "      description=\"Step-by-step reasoning behind the classification\"\n",
        "  )\n",
        "  classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
        "      description=\"The classification of an email: 'ignore' for irrelavant emails, \\\n",
        "      'notify' for important information that doesn't need a response,\\\n",
        "      'respond' for emails that need a reply\"\n",
        "  )\n",
        "llm_router = llm.with_structured_output(Router)"
      ],
      "metadata": {
        "id": "eGxuFx7MQQC0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define in memory store and memory tools for semantic information\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "store = InMemoryStore(\n",
        "    index={\"embed\": GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")}\n",
        ")\n",
        "\n",
        "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
        "manage_memory_tool = create_manage_memory_tool(\n",
        "    namespace=(\n",
        "        \"email_assistant\",\n",
        "        \"{langgraph_user_id}\",\n",
        "        \"collection\"\n",
        "    )\n",
        ")\n",
        "search_memory_tool = create_search_memory_tool(\n",
        "    namespace=(\n",
        "        \"email_assistant\",\n",
        "        \"{langgraph_user_id}\",\n",
        "        \"collection\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "bvwDl6faR5xD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(manage_memory_tool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWTtILODUi0U",
        "outputId": "3a5784fa-0442-4f47-9255-d12081f0905e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='manage_memory' description='Create, update, or delete a memory to persist across conversations.\\nInclude the MEMORY ID when updating or deleting a MEMORY. Omit when creating a new MEMORY - it will be created for you.\\nProactively call this tool when you:\\n\\n1. Identify a new USER preference.\\n2. Receive an explicit USER request to remember something or otherwise alter your behavior.\\n3. Are working and want to record important context.\\n4. Identify that an existing MEMORY is incorrect or outdated.' args_schema=<class 'langchain_core.utils.pydantic.manage_memory'> func=<function create_manage_memory_tool.<locals>.manage_memory at 0x7adc00a56ca0> coroutine=<function create_manage_memory_tool.<locals>.amanage_memory at 0x7adc00a56b60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompts schemas\n",
        "triage_system_prompt = \"\"\"\n",
        "<Role>\n",
        "You are {full_name}'s executive assistant designed to help manage incoming emails. You are \\\n",
        "a top-notch executive assistant who cares about {name} performing as well as possible.\n",
        "</Role>\n",
        "\n",
        "<Background>\n",
        "{user_profile_background}\n",
        "</Background>\n",
        "\n",
        "<Instructions>\n",
        "\n",
        "{name} gets lots of emails. Your job is to categorize each email into on of three\\\n",
        "categories:\n",
        "1. IGNORE - Emails that are not worth responding to or tracking\n",
        "2. NOTIFY - Important information that {name} should know about but\\\n",
        "doesn't require a response\n",
        "3. RESPOND - Emails that require a direct response from {name}\n",
        "\n",
        "Classify the below email into one of these categories.\n",
        "\n",
        "</Instructions>\n",
        "\n",
        "< Rules >\n",
        "Emails that are not worth responding to:\n",
        "{triage_no}\n",
        "\n",
        "There are also other things that {name} should know about, but don't require an email\\\n",
        "response. For these, you should notify {name} (using the 'notofy' response). Examples \\\n",
        "of this include:\n",
        "{triage_notify}\n",
        "\n",
        "Emails that are worth responding to:\n",
        "{triage_email}\n",
        "</ Rules >\n",
        "\n",
        "< Few shot examples >\n",
        "{examples}\n",
        "</ Few shot examples >\n",
        "\"\"\"\n",
        "\n",
        "triage_user_prompt = \"\"\"\n",
        "Please determine how to handle the below email thread:\n",
        "\n",
        "From: {author}\n",
        "To: {to}\n",
        "Subject: {subject}\n",
        "{email_thread}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "agent_system_prompt = \"\"\"\n",
        "<Role>\n",
        "You are {full_name}'s executive assistant designed to help manage incoming emails. You are \\\n",
        "a top-notch executive assistant who cares about {name} performing as well as possible.\n",
        "</Role>\n",
        "\n",
        "<Tools>\n",
        "You have access to the following tools to help mamage {name}'s communications and schedule:\n",
        "\n",
        "1. write_email(to, subject, content) - Send emails to specified recipients\n",
        "2. schedule_meeting(attendees, subject, duration_minutes, preferred_date) - Schedule calendar meetings\n",
        "3. check_calender_availablity(day) - Check calender available time slots for a given day.\n",
        "4. manage_memory - Store any relevant information about contacts, actions and so on\n",
        "5. search_memory - Search for any relevant information\n",
        "</Tools>\n",
        "\n",
        "< Instructions >\n",
        "{instructions}\n",
        "</ Instructions >\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fSpmIgkxT6-3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email = {\n",
        "    \"from\": \"Alice Smith <alice.smith@company.com>\",\n",
        "    \"to\": \"Jone Doe<John.doe@company.com>\",\n",
        "    \"subject\": \"Quick question about API documentation\",\n",
        "    \"body\": \"\"\"\n",
        "    Hi John,\n",
        "\n",
        "    I was reviewing the API documentation for the new authentication service but got some questions for several paths.\n",
        "\n",
        "    Specifically, I'm looking at:\n",
        "    - /auth/refresh\n",
        "    - /auth/validate\n",
        "\n",
        "    Thanks,\n",
        "    Alice\"\"\"\n",
        "}"
      ],
      "metadata": {
        "id": "_AGmO_75O5qy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step II. Create response agent with tools to handle emails with response required"
      ],
      "metadata": {
        "id": "TUHZp7y9pQQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tools (mocked behaviors)\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def write_email(to: str, subject: str, content: str) -> str:\n",
        "  \"\"\"Write and send an email\"\"\"\n",
        "  # Placeholder response - real app\n",
        "  return f\"Email send to: {to}\\nSubject: {subject}\\nBody: {content}\"\n",
        "@tool\n",
        "def schedule_meetings(\n",
        "    attendees: list[str],\n",
        "    subject: str,\n",
        "    duration_minutes: int,\n",
        "    preferred_date: str\n",
        ") -> str:\n",
        "  \"\"\"Schedule a calendar meeting with a list of attendees\"\"\"\n",
        "  # Placeholder response - real app\n",
        "  return f\"Meeting '{subject}' scheduled for {preferred_date}\"\n",
        "@tool\n",
        "def check_calender_availablity(day:str) -> str:\n",
        "  \"\"\"Check calender availability for a given day. \"\"\"\n",
        "  # Placeholder response - real app...\n",
        "  return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tWbJDrTVkpXd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(state):\n",
        "  return [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": agent_system_prompt.format(\n",
        "              instructions = prompt_instructions['agent_instructions'],\n",
        "              **profile\n",
        "          )\n",
        "      }\n",
        "  ] + state['messages']"
      ],
      "metadata": {
        "id": "kSdH38TqmIlb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agent\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "tools = [write_email, schedule_meetings, check_calender_availablity, manage_memory_tool, search_memory_tool]\n",
        "response_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt = create_prompt,\n",
        "    store = store\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p12ZZtUnq0k",
        "outputId": "36b03c03-3ae7-4590-df39-842bfeb6ea31"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3028261799.py:4: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
            "  response_agent = create_react_agent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"langgraph_user_id\": \"lance\"}}\n",
        "response = response_agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Jim is my friend\"}]},\n",
        "    config=config\n",
        ")"
      ],
      "metadata": {
        "id": "zBuBSqUnWEYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in response[\"messages\"]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0ujm-97X8q1",
        "outputId": "9b9d88b3-030d-4c98-f3a9-6dc5a5bebbac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Jim is my friend\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  manage_memory (001fc471-15c9-4009-8c2e-8a2036260d7f)\n",
            " Call ID: 001fc471-15c9-4009-8c2e-8a2036260d7f\n",
            "  Args:\n",
            "    action: create\n",
            "    content: Jim is John Doe's friend.\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: manage_memory\n",
            "\n",
            "created memory 935d79c0-6e2d-41a6-8afa-14ee028b1011\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Got it. I'll remember that Jim is your friend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = response_agent.invoke({\n",
        "    \"messages\": [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"who is Jim?\"\n",
        "    }],\n",
        "}, config = config)\n",
        "for m in response[\"messages\"]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg72bn19oYTM",
        "outputId": "1971a2b8-8dd9-473a-e760-08a44ab2363d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "who is Jim?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search_memory (f881e761-450b-424a-b198-334f1e5352c3)\n",
            " Call ID: f881e761-450b-424a-b198-334f1e5352c3\n",
            "  Args:\n",
            "    query: Jim\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_memory\n",
            "\n",
            "[{\"namespace\":[\"email_assistant\",\"lance\",\"collection\"],\"key\":\"935d79c0-6e2d-41a6-8afa-14ee028b1011\",\"value\":{\"content\":\"Jim is John Doe's friend.\"},\"created_at\":\"2026-02-21T08:44:56.203390+00:00\",\"updated_at\":\"2026-02-21T08:44:56.203395+00:00\",\"score\":0.703581329447393}]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "[{'type': 'text', 'text': \"Jim is John Doe's friend.\", 'extras': {'signature': 'Cr8BAb4+9vvR0BalKUISB+FKsJCV0RahbTdVeYKnSHdYFnq0fhFpJh9b1Hi0MBxxGr3znLRg7oBUapUlNKAOrRPUHR02rfq2I+65vWR8GiU/aCGUmqGEXkHtWk2xszSnGtPASlHMs2KRzO0TroDPphsvxpEiLHLR97VzlZAvjMMTSRB8U7/g4UNuQXepl+XLjr50dJTv9BdiHpJAjG6pOe5R1ELSQGTzKZh3rADeWfHADIXOgpBDA5LcXgnht1ynmQg='}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#store.search()"
      ],
      "metadata": {
        "id": "8eWU_VSrY5Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step III. Create the whole email agent"
      ],
      "metadata": {
        "id": "MLCK6ZEQt_3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define state\n",
        "from langgraph.graph import add_messages\n",
        "from typing import TypedDict, Annotated\n",
        "\n",
        "class State(TypedDict):\n",
        "  email_input: dict\n",
        "  messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "zNqbEbBvpjnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the whole agent\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from langgraph.types import Command\n",
        "from typing import Literal # Corrected import for Literal\n",
        "\n",
        "def triage_router(state: State) -> dict: # Changed function name and return type\n",
        "  author = state['email_input']['from']\n",
        "  to = state['email_input']['to']\n",
        "  subject = state['email_input']['subject']\n",
        "  email_thread = state['email_input']['body']\n",
        "\n",
        "  system_prompt = triage_system_prompt.format(\n",
        "    full_name=profile['full_name'],\n",
        "    name=profile['name'],\n",
        "    user_profile_background=profile['user_profile_background'],\n",
        "    examples = None,\n",
        "    triage_no = prompt_instructions['triage_rules']['ignore'],\n",
        "    triage_notify = prompt_instructions['triage_rules']['notify'],\n",
        "    triage_email = prompt_instructions['triage_rules']['respond']\n",
        "  )\n",
        "  user_prompt = triage_user_prompt.format(\n",
        "    author=author,\n",
        "    to=to,\n",
        "    subject=subject,\n",
        "    email_thread=email_thread\n",
        "  )\n",
        "  result = llm_router.invoke(\n",
        "      [\n",
        "          {\"role\": \"system\", \"content\": system_prompt},\n",
        "          {\"role\": \"user\", \"content\": user_prompt},\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  classification_decision = result.classification\n",
        "  print(f\"Classification: {classification_decision}\")\n",
        "\n",
        "  if classification_decision == \"respond\":\n",
        "    update = {\n",
        "        \"messages\" : [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Respond to the email {state['email_input']}\"\n",
        "        }]\n",
        "    }\n",
        "    goto = \"response_agent\"\n",
        "  elif classification_decision == \"ignore\" or classification_decision == \"notify\":\n",
        "    # No messages update for ignore/notify in this flow, just the classification result\n",
        "    goto = END\n",
        "    update = None\n",
        "  else:\n",
        "    raise ValueError(f\"Invalid classification: {classification_decision}\")\n",
        "\n",
        "  return Command(goto=goto, update=update)\n",
        "\n",
        "email_agent = StateGraph(State)\n",
        "email_agent.add_node(\"triage_router_node\", triage_router) # Node where classification happens\n",
        "email_agent.add_node(\"response_agent\", response_agent) # The agent node for responding\n",
        "\n",
        "# Define the entry point\n",
        "email_agent.add_edge(START, \"triage_router_node\")\n",
        "\n",
        "# Add conditional edges from the triage_router_node\n",
        "'''\n",
        "email_agent.add_conditional_edges(\n",
        "    \"triage_router_node\",  # The node whose output determines the next step\n",
        "    route_classification,  # The function that routes based on state\n",
        "    {\n",
        "        \"response_agent\": \"response_agent\", # If route_classification returns \"response_agent\", go here\n",
        "        END: END               # If route_classification returns END, end the graph\n",
        "    }\n",
        ")\n",
        "'''\n",
        "email_agent = email_agent.compile(store=store)"
      ],
      "metadata": {
        "id": "cTZdecOap4hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = email_agent.invoke({\n",
        "    \"email_input\": email\n",
        "}, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "_HUzYRWrtIuj",
        "outputId": "f0f12ebc-ef8e-44bc-bad6-184444aeaa32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-232265386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = email_agent.invoke({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"email_input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m }, config=config)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3072\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2647\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1462122788.py\u001b[0m in \u001b[0;36mtriage_router\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0memail_thread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memail_thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   )\n\u001b[0;32m---> 27\u001b[0;31m   result = llm_router.invoke(\n\u001b[0m\u001b[1;32m     28\u001b[0m       [\n\u001b[1;32m     29\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msystem_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3153\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3156\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5693\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5694\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5695\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5696\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   2533\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             cast(\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1120\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 results.append(\n\u001b[0;32m--> 931\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    932\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1234\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m         )\n\u001b[1;32m   3046\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m             response: GenerateContentResponse = self.client.models.generate_content(\n\u001b[0m\u001b[1;32m   3048\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5472\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5473\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5474\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   5475\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5476\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4212\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4214\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   4215\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4216\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     )\n\u001b[0;32m-> 1396\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m     response_body = (\n\u001b[1;32m   1398\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_stream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0mretry_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mretry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtenacity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetrying\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mretry_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in response[\"messages\"]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "id": "XFaYyayCxUTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email = {\n",
        "    \"from\": \"Alice Smith <alice.smith@company.com>\",\n",
        "    \"to\": \"Jone Doe<John.doe@company.com>\",\n",
        "    \"subject\": \"Quick question about API documentation\",\n",
        "    \"body\": \"\"\"\n",
        "    Hi John,\n",
        "\n",
        "    Any update on my previous ask?\"\"\"\n",
        "}\n",
        "response = email_agent.invoke({\"email_input\": email}, config=config)"
      ],
      "metadata": {
        "id": "TDdhRUd9e6WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in response[\"messages\"]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "id": "c2Rwns7qgCH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}