{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPuVO8AaLFcg9FWDjFjy2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enya-yx/LangChain-Courses/blob/main/tool_and_routing_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"langchain-google-genai\" \"langchain\" \"langchain-core\" \"langgraph-prebuilt\" \"google-generativeai\" \"langchain_community\" \"docarray\" \"langchain_experimental\""
      ],
      "metadata": {
        "id": "sIdyIP6YPtKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bb58df-7d35-4437-cfa0-0e815e8cd274"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting docarray\n",
            "  Downloading docarray-0.41.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.4.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-prebuilt) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.1.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.1.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "  Downloading langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langgraph-prebuilt\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from docarray) (3.11.4)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.12/dist-packages (from docarray) (13.9.4)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from docarray)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph-prebuilt) (1.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.1.0->docarray) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.1.0->docarray) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->docarray)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docarray-0.41.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, types-requests, requests, mypy-extensions, marshmallow, typing-inspect, docarray, dataclasses-json, langchain-core, langchain-text-splitters, langgraph-prebuilt, langchain, langchain-google-genai, langchain_community, langchain_experimental\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "  Attempting uninstall: langgraph-prebuilt\n",
            "    Found existing installation: langgraph-prebuilt 1.0.5\n",
            "    Uninstalling langgraph-prebuilt-1.0.5:\n",
            "      Successfully uninstalled langgraph-prebuilt-1.0.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.1.0\n",
            "    Uninstalling langchain-1.1.0:\n",
            "      Successfully uninstalled langchain-1.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langgraph 1.0.3 requires langgraph-prebuilt<1.1.0,>=1.0.2, but you have langgraph-prebuilt 1.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 docarray-0.41.0 filetype-1.2.0 langchain-0.3.27 langchain-core-0.3.80 langchain-google-genai-2.0.10 langchain-text-splitters-0.3.11 langchain_community-0.3.31 langchain_experimental-0.3.4 langgraph-prebuilt-1.0.1 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 types-requests-2.32.4.20250913 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('google_api_key')\n",
        "# Configure the generative AI library with your API key\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
      ],
      "metadata": {
        "id": "6gPZp3CQXQzM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Define llm\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "UL4c9YZWO0X7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tools by decorator and using pandatic class as args\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.agents import tool\n",
        "\n",
        "class SearchInput(BaseModel):\n",
        "  query: str = Field(description=\"thing to search for\")\n",
        "\n",
        "@tool(args_schema=SearchInput)\n",
        "def search(query: str) -> str:\n",
        "  \"\"\"Search for weather online\"\"\"\n",
        "  return \"42f\"\n",
        "search.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAw3N08n_F08",
        "outputId": "fe925dbb-d1e6-4687-ec13-82f7c46c2123"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': {'description': 'thing to search for',\n",
              "  'title': 'Query',\n",
              "  'type': 'string'}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the first tool to query current temperature for a position\n",
        "import requests\n",
        "class Position(BaseModel):\n",
        "  latitude: float = Field(description=\"latitude of the location\")\n",
        "  longitude: float = Field(description=\"longitude of the location\")\n",
        "\n",
        "@tool(args_schema=Position)\n",
        "def get_current_temperature(latitude: float, longitude: float) -> str:\n",
        "  \"\"\"Get the current temperature\"\"\"\n",
        "\n",
        "  BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "  params = {\n",
        "    \"latitude\": latitude,\n",
        "    \"longitude\": longitude,\n",
        "    \"hourly\": \"temperature_2m\",\n",
        "    \"forecast_days\": 1,\n",
        "  }\n",
        "  response = requests.get(BASE_URL, params=params)\n",
        "  if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    hourly_data = data[\"hourly\"]\n",
        "    temperature_2m = hourly_data[\"temperature_2m\"]\n",
        "    unit = data[\"hourly_units\"][\"temperature_2m\"]\n",
        "\n",
        "    return f\"The current temperature is: {temperature_2m[0]}{unit}\"\n",
        "  else:\n",
        "    raise Exception(f\"Request failed with status code {response.status_code}\")\n",
        "\n",
        "\n",
        "get_current_temperature.invoke({\"latitude\": 13, \"longitude\":14})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DP6W12QvAzPe",
        "outputId": "afa83ab8-7a90-44b5-8d21-c1160b61bf94"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is: 21.3°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "get_current_temperature_function = format_tool_to_openai_function(get_current_temperature)\n",
        "get_current_temperature_function\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg5dl_7eCsJn",
        "outputId": "18c5de65-ee0a-4a9f-ba74-72d49fccf879"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1714603674.py:2: LangChainDeprecationWarning: The function `_format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
            "  get_current_temperature_function = format_tool_to_openai_function(get_current_temperature)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'get_current_temperature',\n",
              " 'description': 'Get the current temperature',\n",
              " 'parameters': {'properties': {'latitude': {'description': 'latitude of the location',\n",
              "    'type': 'number'},\n",
              "   'longitude': {'description': 'longitude of the location',\n",
              "    'type': 'number'}},\n",
              "  'required': ['latitude', 'longitude'],\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt and bind function to llm\n",
        "template_string = \"What is the current temperature at position latitude: {latitude}, longitude: {longitude}?\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"latitude\", \"longitude\"],\n",
        "    template=template_string\n",
        ")\n",
        "#message_test = prompt.format(latitude=13, longitude=14)\n",
        "#message_test\n",
        "\n",
        "llm_with_function = llm.bind(functions = [get_current_temperature_function])\n",
        "\n",
        "chain = prompt | llm_with_function\n",
        "res = chain.invoke({\"latitude\": 13, \"longitude\":14})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjh4pOk5GKW-",
        "outputId": "bdece491-00c9-4a00-bb06-cad007eb4656"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\"latitude\": 13.0, \"longitude\": 14.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--c500f42d-7e12-4aaa-8b22-6fee19445c55-0' tool_calls=[{'name': 'get_current_temperature', 'args': {'latitude': 13.0, 'longitude': 14.0}, 'id': '1488a011-7d96-45d9-baa1-4d2aeed1322e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 75, 'output_tokens': 24, 'total_tokens': 177, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYaAE26PT5-g",
        "outputId": "16eba802-ce4a-4c4e-9070-2782d322cfda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=8783874a406d08f54cd7373e652765003eae80e98fa786c3ed39ff333753a666\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the second tool to use wikipedia\n",
        "import wikipedia\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "  \"\"\"Search wikipedia for the given query and get page summaries\"\"\"\n",
        "  page_titles = wikipedia.search(query)\n",
        "  summaries = []\n",
        "  for page_title in page_titles[:3]:\n",
        "    try:\n",
        "      wiki_pedia_page = wikipedia.page(page_title)\n",
        "      summaries.append(f\"Page: {page_title}\\nSummary: {wiki_pedia_page.summary}\")\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "      print(f\"Skipping disambiguation page: {page_title}\")\n",
        "\n",
        "  if not summaries:\n",
        "    return \"No good Wikipedia Search Result was found\"\n",
        "\n",
        "  return \"\\n\\n\".join(summaries)\n",
        "\n",
        "search_wikipedia_function = format_tool_to_openai_function(search_wikipedia)"
      ],
      "metadata": {
        "id": "6HQFmxVtSDrF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bind model with multiple functions\n",
        "llm_multi_function = llm.bind(functions = [get_current_temperature_function, search_wikipedia_function])\n",
        "res1 = llm_multi_function.invoke(\"What is the current weather at the position: latitude 13, longitide 14 right now?\")\n",
        "res2 = llm_multi_function.invoke(\"Give a short introduction about the game Werewolves Kill\")\n",
        "print(res1)\n",
        "print(res2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLzMAT8VTHAL",
        "outputId": "d21120d7-58aa-467d-89df-0e1dc1acc425"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\"latitude\": 13.0, \"longitude\": 14.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--6c79c419-c426-451e-9d97-e3f2e0635b3c-0' tool_calls=[{'name': 'get_current_temperature', 'args': {'latitude': 13.0, 'longitude': 14.0}, 'id': '0e65314e-bd4d-41ad-b393-564232ca5b25', 'type': 'tool_call'}] usage_metadata={'input_tokens': 121, 'output_tokens': 24, 'total_tokens': 230, 'input_token_details': {'cache_read': 0}}\n",
            "content='' additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\"query\": \"Werewolves Kill game\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--b3af06a3-1382-4d68-9860-33b6fdf2996e-0' tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'Werewolves Kill game'}, 'id': '1da1297f-d823-4514-80a5-ff3d55cfd945', 'type': 'tool_call'}] usage_metadata={'input_tokens': 108, 'output_tokens': 18, 'total_tokens': 181, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40cc0b11",
        "outputId": "7942ece2-75bc-439f-be82-ea634554681f"
      },
      "source": [
        "# Define the executor as a rounter to trigger tools or return the content\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "def tool_executor(message: BaseMessage):\n",
        "    if message.tool_calls:\n",
        "        tool_call = message.tool_calls[0]\n",
        "        tool_name = tool_call['name']\n",
        "        tool_args = tool_call['args']\n",
        "        tools = {\n",
        "          \"get_current_temperature\": get_current_temperature,\n",
        "          \"search_wikipedia\": search_wikipedia\n",
        "        }\n",
        "\n",
        "        # Assuming get_current_temperature is accessible in the scope\n",
        "        if tool_name in tools:\n",
        "            return tools[tool_name].invoke(tool_args)\n",
        "        else:\n",
        "            # Handle other tools if necessary, or raise an error\n",
        "            return f\"Unknown tool: {tool_name}\"\n",
        "    else:\n",
        "        return message.content # Return the LLM's content if no tool call\n",
        "\n",
        "tool_execution_runnable = RunnableLambda(tool_executor)\n",
        "\n",
        "print(\"Defined tool_executor function and tool_execution_runnable.\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined tool_executor function and tool_execution_runnable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6f0b5cf9",
        "outputId": "fec5125f-798c-4566-9625-efed90e227fc"
      },
      "source": [
        "# Add tool executor to the chain to trigger the function automatically\n",
        "# from langchain.agents.output_parsers import JsonOutputFunctionsParser\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "full_chain = prompt | llm_multi_function | tool_execution_runnable"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is: 24.4°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain.invoke({\"input\": \"What is the current weather at the position: latitude 13, longitide 14 right now?\"})"
      ],
      "metadata": {
        "id": "TGGhEcJ4pY_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain.invoke({\"input\": \"Hi, I'm Yx\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fLNrEAMRjaDb",
        "outputId": "a9e178fe-1450-403f-bd9b-6f16f8719690"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Yx! Nice to meet you. How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain.invoke({\"input\": \"What is the game of Werewolves Kill?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "arEX4R9wpaj7",
        "outputId": "430416f9-cf03-481c-cc8f-7cc601e7ba00"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Mafia (party game)\\nSummary: Mafia, also known as Werewolf, is a social deduction game created in 1986 by Dimitry Davidoff, then a psychology student at Moscow State University. The game models a conflict between two groups: an informed minority (the mafiosi or the werewolves) and an uninformed majority (the villagers). At the start of the game, each player is secretly assigned a role affiliated with one of these teams. The game has two alternating phases: first, a night-phase, during which those with night-killing-powers may covertly kill other players, and second, a day-phase, in which all surviving players debate and vote to eliminate a suspect. The game continues until a faction achieves its win condition; for the village, this usually means eliminating the evil minority, while for the minority, this usually means reaching numerical parity with the village and eliminating any rival evil groups.\\n\\n\\n\\nPage: Werewolves Within (film)\\nSummary: Werewolves Within is a 2021 American comedy horror film directed by Josh Ruben and written by Mishna Wolff, based on the video game of the same name from Red Storm Entertainment. It stars Sam Richardson, Milana Vayntrub, George Basil, Sarah Burns, Michael Chernus, Catherine Curtin, Wayne Duvall, Harvey Guillén, Rebecca Henderson, Cheyenne Jackson, Michaela Watkins, and Glenn Fleshler. The film follows a group of people in a small Vermont town who get trapped in a snowstorm while suspecting one of them is a werewolf.\\nPlans for a Werewolves Within film adaptation began in October 2018, with Wolff writing the script and Ubisoft Motion Pictures producing it. The cast was announced in early 2020 and principal photography began in February 2020.\\nWerewolves Within had its world premiere at the Tribeca Film Festival on June 16, 2021, and began a limited theatrical release in the United States on June 25, 2021, followed by video on demand on July 2, by IFC Films. The film received generally positive reviews from critics for its screenplay, characters, and humor, becoming the highest-rated film based on a video game on Rotten Tomatoes and Metacritic.\\n\\nPage: Werewolf Game\\nSummary: Werewolf Game is a 2025 American horror film written by Jackie Payne, directed by Payne and Cara Brennan and starring Tony Todd, Lydia Hearst, Bai Ling, and Robert Picardo.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent; Apply 'MessagePlaceholder' when define prompt to pass information from each chain invoke\n",
        "from langchain.prompts import MessagesPlaceholder\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "prompt_with_holder = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scrachpad\"),\n",
        "])\n",
        "chain = prompt_with_holder | llm_multi_function | OpenAIFunctionsAgentOutputParser()"
      ],
      "metadata": {
        "id": "G_Bdg7sQxPGf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = chain.invoke({\"input\": \"What is the game of Werewolves Kill?\", \"agent_scrachpad\": []})\n"
      ],
      "metadata": {
        "id": "_pVlBk6OyIs5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1.message_log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_SdxIow1rtD",
        "outputId": "3ecc3ead-4ee8-4358-8954-a1ea7244bf25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\"query\": \"Werewolves Kill game\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--102a31da-029a-4d9d-9cd7-5351e7e53a3c-0', tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'Werewolves Kill game'}, 'id': '33be783c-d0f6-4292-859f-1f9b144f788d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 112, 'output_tokens': 18, 'total_tokens': 165, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = result1.tool\n",
        "obersavation = search_wikipedia.invoke(result1.tool_input)\n",
        "print(obersavation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLtHZJURzgPT",
        "outputId": "fce74adf-526a-4a21-c831-607fb7d83245"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: Mafia (party game)\n",
            "Summary: Mafia, also known as Werewolf, is a social deduction game created in 1986 by Dimitry Davidoff, then a psychology student at Moscow State University. The game models a conflict between two groups: an informed minority (the mafiosi or the werewolves) and an uninformed majority (the villagers). At the start of the game, each player is secretly assigned a role affiliated with one of these teams. The game has two alternating phases: first, a night-phase, during which those with night-killing-powers may covertly kill other players, and second, a day-phase, in which all surviving players debate and vote to eliminate a suspect. The game continues until a faction achieves its win condition; for the village, this usually means eliminating the evil minority, while for the minority, this usually means reaching numerical parity with the village and eliminating any rival evil groups.\n",
            "\n",
            "\n",
            "\n",
            "Page: Werewolves Within (film)\n",
            "Summary: Werewolves Within is a 2021 American comedy horror film directed by Josh Ruben and written by Mishna Wolff, based on the video game of the same name from Red Storm Entertainment. It stars Sam Richardson, Milana Vayntrub, George Basil, Sarah Burns, Michael Chernus, Catherine Curtin, Wayne Duvall, Harvey Guillén, Rebecca Henderson, Cheyenne Jackson, Michaela Watkins, and Glenn Fleshler. The film follows a group of people in a small Vermont town who get trapped in a snowstorm while suspecting one of them is a werewolf.\n",
            "Plans for a Werewolves Within film adaptation began in October 2018, with Wolff writing the script and Ubisoft Motion Pictures producing it. The cast was announced in early 2020 and principal photography began in February 2020.\n",
            "Werewolves Within had its world premiere at the Tribeca Film Festival on June 16, 2021, and began a limited theatrical release in the United States on June 25, 2021, followed by video on demand on July 2, by IFC Films. The film received generally positive reviews from critics for its screenplay, characters, and humor, becoming the highest-rated film based on a video game on Rotten Tomatoes and Metacritic.\n",
            "\n",
            "Page: Werewolf Game\n",
            "Summary: Werewolf Game is a 2025 American horror film written by Jackie Payne, directed by Payne and Cara Brennan and starring Tony Todd, Lydia Hearst, Bai Ling, and Robert Picardo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "# result1 is an AgentActionMessageLog object. Its message_log contains the AIMessage.\n",
        "# obersavation is the string result from the tool execution.\n",
        "\n",
        "# Construct the agent_scrachpad correctly:\n",
        "# 1. The AIMessage from the LLM that suggested the tool call\n",
        "# 2. A ToolMessage containing the observation (the result of the tool execution)\n",
        "agent_scratchpad_messages = [\n",
        "    result1.message_log[0], # The AIMessage from the LLM\n",
        "    ToolMessage(content=obersavation, tool_call_id=result1.message_log[0].tool_calls[0]['id']) # The result of the tool execution\n",
        "]\n",
        "\n",
        "result2 = chain.invoke({\n",
        "    \"input\": \"What is the game of Werewolves Kill?\",\n",
        "    \"agent_scrachpad\": agent_scratchpad_messages\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_14aAEor03gb",
        "outputId": "6a2322a0-a506-40ca-95de-2d1da9d8891b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return_values={'output': '\"Werewolves Kill\" is likely a reference to the social deduction game \"Mafia,\" also known as \"Werewolf.\" In this game, players are secretly assigned roles as either an informed minority (werewolves/mafia) or an uninformed majority (villagers). The game alternates between a \"night\" phase where werewolves secretly \"kill\" players, and a \"day\" phase where all surviving players debate and vote to eliminate a suspect. The goal for the villagers is to eliminate the werewolves, while the werewolves aim to achieve numerical parity with the villagers.'} log='\"Werewolves Kill\" is likely a reference to the social deduction game \"Mafia,\" also known as \"Werewolf.\" In this game, players are secretly assigned roles as either an informed minority (werewolves/mafia) or an uninformed majority (villagers). The game alternates between a \"night\" phase where werewolves secretly \"kill\" players, and a \"day\" phase where all surviving players debate and vote to eliminate a suspect. The goal for the villagers is to eliminate the werewolves, while the werewolves aim to achieve numerical parity with the villagers.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZroMTcvP2XVd",
        "outputId": "7a74130c-11a6-4703-9bf0-fc121f8d7418"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='search_wikipedia', tool_input={'query': 'Werewolves Kill'}, log=\"\\nInvoking: `search_wikipedia` with `{'query': 'Werewolves Kill'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\"query\": \"Werewolves Kill\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--481a333c-5366-4e85-a0fb-c7de66636ab2-0', tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'Werewolves Kill'}, 'id': '7b126815-a88e-4e3e-8b18-61ef464fc2bf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 112, 'output_tokens': 17, 'total_tokens': 164, 'input_token_details': {'cache_read': 0}})])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8wd7rh2aA2",
        "outputId": "8c019f7c-6a9d-411d-c2f4-d44b3c9d0da9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': '\"Werewolves Kill\" is likely a reference to the social deduction game \"Mafia,\" also known as \"Werewolf.\" In this game, players are secretly assigned roles as either an informed minority (werewolves/mafia) or an uninformed majority (villagers). The game alternates between a \"night\" phase where werewolves secretly \"kill\" players, and a \"day\" phase where all surviving players debate and vote to eliminate a suspect. The goal for the villagers is to eliminate the werewolves, while the werewolves aim to achieve numerical parity with the villagers.'}, log='\"Werewolves Kill\" is likely a reference to the social deduction game \"Mafia,\" also known as \"Werewolf.\" In this game, players are secretly assigned roles as either an informed minority (werewolves/mafia) or an uninformed majority (villagers). The game alternates between a \"night\" phase where werewolves secretly \"kill\" players, and a \"day\" phase where all surviving players debate and vote to eliminate a suspect. The goal for the villagers is to eliminate the werewolves, while the werewolves aim to achieve numerical parity with the villagers.')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to run steps based on return type\n",
        "from langchain.schema import AgentFinish\n",
        "tools = {\n",
        "        \"get_current_temperature\": get_current_temperature,\n",
        "        \"search_wikipedia\": search_wikipedia\n",
        "  }\n",
        "def run_agent(user_input):\n",
        "  intermediate_steps = []\n",
        "  while True:\n",
        "    result = chain.invoke({\"input\": user_input, \"agent_scrachpad\": intermediate_steps})\n",
        "    if isinstance(result, AgentFinish):\n",
        "      return result\n",
        "    else:\n",
        "      tool = tools[result.tool]\n",
        "      obersavation = tool.run(result.tool_input)\n",
        "      intermediate_steps = [\n",
        "        result.message_log[0], # The AIMessage from the LLM\n",
        "        ToolMessage(content=obersavation, tool_call_id=result.message_log[0].tool_calls[0]['id']) # The result of the tool execution\n",
        "      ]\n"
      ],
      "metadata": {
        "id": "4-ibLn0NHF3w"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is the current weather at the position: latitude 13, longitide 14 right now?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-8_FZbhJ3Ub",
        "outputId": "936277f0-7fe6-4bf6-b7fe-ec8c387dbaf8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': 'The current temperature is 21.3°C.'}, log='The current temperature is 21.3°C.')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pending: Create a conversation agent with memory\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scrachpad\"),\n",
        "])\n",
        "chain = prompt | llm | OpenAIFunctionsAgentOutputParser()\n",
        "agent_chain = RunnablePassthrough.assign(agent_scrachpad = lambda x: format_tool_to_openai_function(x[\"intermediate_steps\"]))"
      ],
      "metadata": {
        "id": "uItepdA7L5zp"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}